# DesktopChatPat - Document

2022年8月

## 一、实验任务

内容： **A lovely Desktop at your Command 	《可爱桌宠听你话》**

要求： 桌宠的生活，散步，在空闲中游玩，跟随你的鼠标，和你玩，与你交谈，识别你的声音命令，并与你互动。



## 二、已完成任务

**实验要求**

1. 语音识别与互动、问答
2. 有自己的情绪，会随着主人互动而变化，表现为立绘的变化
3. 鼠标捕获， 可以抓猫猫，丢到空中落下，可以让猫猫抓你的鼠标， 可以让他退出时灰溜溜的溜出屏幕等等有趣的特性
4. 纯净模式下, 猫猫坐定不动，不吵不闹
5. 支持语音开关机, 截图等等系统功能, 可以自己扩展diy
6. 支持diy图像素材, 参见psd文件
7. 一些设置信息，比如主人名字和猫猫名字，以及当前模式设定信息，通过写入参数文件的方式保存， 支持语音设定和修改、或是菜单栏选择

针对此我们基于pyqt5实现了支持语音识别对话的互动桌宠



![image-20220814173320129](%E3%80%8A%E6%9A%91%E6%9C%9FPython%E8%AF%BE%E3%80%8B%E5%A4%A7%E4%BD%9C%E4%B8%9A%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A.assets/image-20220814173320129.png)



## 三、总体方案设计

### 任务分析与分解

![image-20220814172714975](%E3%80%8A%E6%9A%91%E6%9C%9FPython%E8%AF%BE%E3%80%8B%E5%A4%A7%E4%BD%9C%E4%B8%9A%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A.assets/image-20220814172714975-16724945914641.png)



### UI设计与图像

以下是我们简化后的UML调用关系图:

![image-20220814173740865](%E3%80%8A%E6%9A%91%E6%9C%9FPython%E8%AF%BE%E3%80%8B%E5%A4%A7%E4%BD%9C%E4%B8%9A%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A.assets/image-20220814173740865.png)

可以看到我们的UI设计主要分为4个模块， 也即对应的四个`Qthread`线程：

主线程：`DesktopPet` 类

包括了多种状态的切换（行走、坐定、跳跃、被鼠标抓起来等等）、同时在桌面上模拟宠物的物理特性包括重力加速度等等

辅线程：`MyMenu`类

重写右键菜单栏，仿win10做了动态的菜单显示， 同时实现了哑光磨砂效果， 此外通过写入文件来保留设置

辅线程：`recordButton`类

即录音按钮及其录音功能的实现， 对于图标实现了动态效果， 调用sounddevice soundfile库实现录音并通知主线程

辅线程：`DisplayWindow`类

主线程收到录音结束的信号后， 语音识别开始， 并将结果返回至display window， 显示在弹幕式对话框上

![image-20220814185320997](%E3%80%8A%E6%9A%91%E6%9C%9FPython%E8%AF%BE%E3%80%8B%E5%A4%A7%E4%BD%9C%E4%B8%9A%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A.assets/image-20220814185320997.png)



### 语音识别与问答模块

- **基本需求与技术方案**

  - **基本需求**：对录音线程录制的wav文件进行流式或非流式的处理，实现中文语音识别；并建立问答系统，对语音识别的结果进行回应——要求能够回答基本日常对话、简单的知识问答、以及对命令做出响应（包括截图、播放音乐、改名等）。

  - **技术方案与效果**：

    - 对语音识别，采取非流式识别的方式，在录音线程结束录音后对一段音频文件统一处理。将中文语音转文字的任务其拆分成**语音转拼音的语音模型**，和**拼音转文字的语言模型**。本项目使用**DCNN模型**和**基于概率图的最大熵隐马尔可夫模型**这两个开源预训练模型作为语音模型和语言模型，主要参考[ASRT语音识别项目](https://github.com/nl8590687/ASRT_SpeechRecognition)。

      经实测，对于日常对话和知识问答，语音模型的准确率在80%以上，整个语音识别模型的推理时间在0.5s以内，较好的平衡了准确度和实时性。

    - 对问答系统，选择离线的检索式问答系统，通过访问本地经过预处理的语义资料，计算出问题的答案。语义资料由百度知道中文问答数据集`WebQA`清洗而来。检索算法由以下几本分组成：利用`jieba`库通过隐马尔科夫模型模型分词，利用`tf-idf`模型（词频-逆向文档频率）生成输入问题和数据集问题在向量空间中的表征，最后计算余弦相似度，排序得到结果。

      经实测，该问答系统推理速度仅在0.1s左右，有较好的实时性，且效果稳定。主要参考论文Li, Peng, et al. "Dataset and neural recurrent sequence labeling model for open-domain factoid question answering." *arXiv preprint arXiv:1607.06275* (2016).

- 语音交互部分的**程序流程图**如下所示：

  ```mermaid
  flowchart TD
  b3-->a
  a(PetInteraction.step : 语音转问答结果)-->a1
  subgraph speech_recognition
  a1(self.model.recognize_speech_from_file : 语音模型转拼音)
  a2(处理指令)
  a3(self.langmodel.pinyin_to_text : 语言模型转文字)
  a1--包含关键字-->a2
  a1--不含关键字-->a3
  end
  a3-->b4
  subgraph QA_system
  init-->加载语料库和停用词-->b1(self._split_word : 将数据库中问题转为词袋)-->b2(gensim.corpora.Dictionary : 加载gensim字典)-->b3(加载或生成tfidf模型\n生成webQA中问题特征向量)
  b4(self._split_word : 问题分词)-->b5(self.dictionary.doc2bow	: 词转为向量)-->b6(与数据集中的问题计算余弦相似度\n找出答案)
  end
  b6-->END
  a2-->END
  
  ```
  

### 集成播放器，截图调用

实现了一个简易的本地音乐播放器，包括基本功能：播放暂停、切换前一首后一首音乐，调整播放音量，播放进度条拖拽

<img src="%E3%80%8A%E6%9A%91%E6%9C%9FPython%E8%AF%BE%E3%80%8B%E5%A4%A7%E4%BD%9C%E4%B8%9A%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A.assets/wps5.jpg" alt="wps5" style="zoom:50%;" />

实验了对Windows快捷截图等系统应用的调用，可由语音唤醒。



## 四、细节、难点与创新点

### UI设计

- **亮点1**		全人工手绘桌宠ui, 通过photoshop， 一帧一帧的画出桌宠的动态

<img src="%E3%80%8A%E6%9A%91%E6%9C%9FPython%E8%AF%BE%E3%80%8B%E5%A4%A7%E4%BD%9C%E4%B8%9A%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A.assets/image-20220814192245452.png" alt="image-20220814192245452" style="zoom:50%;" />



- **亮点2**		qss美化+dll磨砂效果制作仿win10的哑光动态特效菜单栏， `Menu` 继承自 `QMenu`，在这个类中通过调用自定义类 `WindowEffect` 的方法来调用win10的api从而实现Aero效果和阴影效果

- **亮点3**		多线程协同， 设置了主线程（桌宠运动线程）, 对话框线程（可以拖动，实时显示，独立于主线程，减轻负担）， 模型计算线程（用于语音识别、问答系统），录音线程， 四者协同完成任务

- **亮点4**		屏幕鼠标追踪和物理特性的模拟，模拟重力的产生，以及跳跃动作追逐鼠标的合理性 



.

### 语音识别与问答模块

- **选择非流式识别+检索式问答系统的考量**

  - 语音识别方案选择：流式识别还是非流式识别？
    - 理论上，流式识别能在录音的过程中就开始识别过程，能更好的减少延迟。但是对于流式识别，模型不能够看到整个句子的全局信息，识别的准确度会降低，而且语言模型也难以在没有得到整个句子的情况下将拼音转为文字。况且已有的非流式识别模型参数量更小，延迟完全可以接收。因此选择了准确度和实时性都能更好兼顾的非流式识别作为算法。
  - 问答系统方案选择：基于本地数据的问答还是基于搜索引擎？
    - 本地数据基本能覆盖大多数的日常对话，以及知识问答。如果利用搜索引擎，数据的质量可能更差，而且延迟更高，不能达到准实时的要求。
    - 那么为什么不试试端到端的聊天问答模型？效果不好，模型太大。
  
- **语音识别系统技术细节** 

  - 该部分较难的是实现准确度与实时性的tradeoff。为此，我们借鉴ASRT项目中的**DCNN模型**和**基于概率图的最大熵隐马尔可夫模型**，将任务拆分为语音模型和语言模型，在0.5s的延迟内实现较好的识别效果。

- **QA问答系统技术细节**

  - **数据集** 借助百度知道中文数据，输入一个问题，以及若干个证据，利用端到端的时序模型堆叠，生成答案。模型结构如下图所示。

    ![屏幕截图(101)](%E3%80%8A%E6%9A%91%E6%9C%9FPython%E8%AF%BE%E3%80%8B%E5%A4%A7%E4%BD%9C%E4%B8%9A%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A.assets/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE(101).png)

    经过该模型处理，能得到一簇问题-答案的键值对，作为webQA数据集。该数据集共有5万+个条目，能涵盖大多数知识性问答。我们对数据进行了提取、过滤与清洗，得到46823条可用数据，部分结果如下：

    ```json
    {
      "8285": {
        "question": "世界上最大的岛屿在哪里？",
        "answer": "格陵兰岛",
        "evidence": "答：中国最大的岛屿是台湾岛，总陆地面积为35915平方公里，属于台湾省；其次是海南岛，总陆地面积为32198平方公里，属于海南剩...世界上最大的岛格陵兰岛（greenland）是世界最大岛，面积2,166,086平方公里(836,330平方哩)。在北美洲东北，北冰洋和大..."
      },
      "8286": {
        "question": "世界上最大的平原是什么",
        "answer": "亚马孙平原",
        "evidence": "亚马孙河是世界流域面积最大的河流,亚马孙河流经的亚马孙平原是世界上面积最大的平原."
      }
    }
    ```

  - **检索算法** 

    - 句子转为词袋：利用`jieba`库调用隐马尔科夫模型模型分词。

    - 对于已经处理好的句子，利用tf-idf算法，将句子d（文档）转化为特征向量$\vec v_{t,d} = [w_{1,d},w_{2,d},...,w_{N,d}]^T$ 其中：

      $$
      w_{t,d} = tf_{t,d} \odot \log \frac{|D|}{|{d' \in D | t \in d'}|}
      $$
      $tf_{t-d}$ 表示词t在文档d中出现的频率。
    
    - 最后对于query（输入的问题）$q$，与数据集中的问题 $d_j$，利用上述特征向量的余弦相似度求出相似度，排序得到答案：
    
      $$
      sim(d_j, q) = \frac{\vec d_j \bullet \vec q}{\lVert \vec d_j\rVert \lVert \vec q \rVert}
      $$

- **整体封装，提供接口**

  - call `PetInteraction.step()` to get a respond(str) from recorded wav file `./output.wav`





## 参考文献

- 语音识别与训练模型：[ASRT语音识别项目](https://github.com/nl8590687/ASRT_SpeechRecognition)

- 对话数据集：Li, Peng, et al. "Dataset and neural recurrent sequence labeling model for open-domain factoid question answering." *arXiv preprint arXiv:1607.06275* (2016).

- 博客：[如何在pyqt中实现带动画的动态QMenu](https://www.cnblogs.com/zhiyiYo/p/14643840.html)

